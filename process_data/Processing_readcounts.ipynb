{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "os.environ[\"HOME\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "import bioinfokit\n",
    "from bioinfokit import analys, visuz\n",
    "from bioinfokit.analys import norm, get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_count = '_starReadsPerGene.out.tab_FILE_PATH'\n",
    "\n",
    "count_files = glob.glob(os.path.join(folder_count, \"*_starReadsPerGene.out.tab\"))\n",
    "count_tableset = []\n",
    "for filename in count_files:\n",
    "    df_count = pd.read_csv(filename, sep = '\\t')\n",
    "    count_tableset.append(df_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_count_f = []\n",
    "for valname in count_files:\n",
    "    spliced_name = valname.split('/')[-1].split('.')[0]\n",
    "    new_count_f.append(spliced_name)\n",
    "dict_count_df = dict(zip(new_count_f, count_tableset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the unstranded reads and sense or anti-sense read according to the data strandedness.\n",
    "for key, val in dict_count_df.items():\n",
    "    val.drop(['unstranded', str(key)], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign the variables with each sample's dataframe : each name of merged columns = dict_count_df[str(key)]\n",
    "well_1 = dict_count_df['well_1']\n",
    "well_2 = dict_count_df['well_2']\n",
    "well_3 = dict_count_df['well_3']\n",
    "chip_1 = dict_count_df['chip_1']\n",
    "chip_2 = dict_count_df['chip_2']\n",
    "chip_3 = dict_count_df['chip_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the sample's read count in one dataframe\n",
    "merge_sample = [well_1, well_2, well_3, chip_1, chip_2, chip_3]\n",
    "merge_count = reduce(lambda left, right : pd.merge(left, right, on = ['gene_ID'], how = 'outer'), merge_sample)\n",
    "merge_count = merge_count.fillna(0)\n",
    "merge_count.columns = [\"gene_ID\", \"Tw1\", \"Tw2\", \"Tw3\", \"C1\", \"C2\", \"C3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the outlier sequences (if 0 appears in more than half of the sample columns, it is designated as an outlier and filtered out.)\n",
    "merge_count['zero_Count'] = (merge_count[[\"Tw1\", \"Tw2\", \"Tw3\", \"C1\", \"C2\", \"C3\"]] == 0).sum(axis=1)\n",
    "merge_count = merge_count[merge_count['zero_Count'] < 4]\n",
    "merge_count = merge_count.drop(['zero_Count'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference file to match the gene id to the gene name is required.\n",
    "#mus_musculus_geneID_genename_v105.txt file is provided in '/process_data/'.\n",
    "\n",
    "folder_ref = 'REFERENCE_FILE_PATH'\n",
    "gene_matching = pd.read_csv('{}/mus_musculus_geneID_genename_v105.txt'.format(folder_ref), sep = ',')\n",
    "gene_id = gene_matching[\"gene_ID\"].tolist()\n",
    "gene = gene_matching[\"gene\"].tolist()\n",
    "new_gene_id = []\n",
    "for i in gene_id:\n",
    "    new_gene = i.split(\".\")[0]\n",
    "    new_gene_id.append(new_gene)\n",
    "    \n",
    "dict_gene = dict(zip(new_gene_id, gene))\n",
    "df_gene = pd.DataFrame.from_dict(data = dict_gene, orient = 'index')\n",
    "df_gene = df_gene.reset_index()\n",
    "df_gene.columns = [\"gene_ID\", \"gene\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process the dataframe to merge the counts of duplicates\n",
    "\n",
    "merge_geneid = pd.merge(df_gene, merge_count, on = 'gene_ID', how = 'inner')\n",
    "merge_geneid = merge_geneid.dropna()\n",
    "merge_geneid2 = merge_geneid.drop([\"gene_ID\"], axis = 1)\n",
    "merge_gene_sum = merge_geneid2.groupby(['gene']).sum()\n",
    "merge_gene_sum = merge_gene_sum.reset_index()\n",
    "genecount_filter = merge_gene_sum[[\"gene\", \"Tw1\", \"Tw2\", \"Tw3\", \"C1\", \"C2\", \"C3\"]]\n",
    "genecount_filter = genecount_filter.drop_duplicates().groupby('gene', sort = False, as_index = False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make the table with gene CPM instead of the count using the bioinfokit toolkit.\n",
    "\n",
    "sum_forCPM = genecount_filter.groupby(['gene']).sum()\n",
    "df_forCPM = sum_forCPM.dropna()\n",
    "nm = norm()\n",
    "nm.cpm(df = df_forCPM)\n",
    "CPM_findf = nm.cpm_norm\n",
    "CPM_findf.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
